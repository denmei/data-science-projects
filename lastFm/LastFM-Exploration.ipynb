{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative item-based filtering for music artists\n",
    "Within this notebook I built a recommender for music artists using a collaborative item-based filtering approach. As a basis, I used the last.fm-dataset which can be found [here](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/index.html). The content of the notebook is based on [this](https://beckernick.github.io/music_recommender/) tutorial.\n",
    "\n",
    "The recommender has been deployed in a sample web-application and can be found [here](https://denmei.github.io/): ![artist_recommender](img/artist_recommender.png)\n",
    "\n",
    "## Theoretical background\n",
    "To provide a better understanding of the approach, here's a small introduction (from Wikipedia, I have to admit).\n",
    "\n",
    "### Collaborative Filtering\n",
    "* Collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration aming multiple agents, viewpoints, data sources etc.\n",
    "* There exist different approaches for collaborative filtering:\n",
    "    * **User-based**: Use ratings from like-minded users to give a recommendation for the active user\n",
    "    * **Item-based**: Build item-item-matrix determining similiarity between pairs of items &rarr; Use tastes of current user to find similar items\n",
    "\n",
    "### Item-based collaborative filtering\n",
    "**How do we get the similarities?**\n",
    "* Look at users who rated both items \n",
    "* Similarity is dependend on the ratings given by users who have rated both of them\n",
    "* There exist a lot of different metrics to measure this similarity, e.g. Cosine-similarity, Euclidian Distance...\n",
    "![Item-based CF](img/icollaborative_filtering.png)\n",
    "\n",
    "**How do we use the similarities?**\n",
    "* We use the most similar items to the ones the user already rated to generate a list of recommendations\n",
    "* *people who rate item X highly, like you, also tend to rate item Y highly, and you haven't rated item Y yet, so you should try it*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "pd.options.display.float_format = \"{:.3f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data + Data Exploration\n",
    "\n",
    "### Load user profiles\n",
    "The user profiles dataset contains data about 359.347 different users, including their id, geneder, age, country and the data when they signed up for the service.\n",
    "![profiles](img/profiles.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    user_id gender    age        country  \\\n",
      "0  00000c289a1829a808ac09c00daf10bc3c4e223b      f 22.000        Germany   \n",
      "1  00001411dc427966b17297bf4d69e7e193135d89      f    nan         Canada   \n",
      "2  00004d2ac9316e22dc007ab2243d6fcb239e707d    NaN    nan        Germany   \n",
      "3  000063d3fe1cf2ba248b9e3c3f0334845a27a6bf      m 19.000         Mexico   \n",
      "4  00007a47085b9aab8af55f52ec8846ac479ac4fe      m 28.000  United States   \n",
      "\n",
      "         signup  \n",
      "0   Feb 1, 2007  \n",
      "1   Dec 4, 2007  \n",
      "2   Sep 1, 2006  \n",
      "3  Apr 28, 2008  \n",
      "4  Jan 27, 2006  \n",
      "Number of rows: 359347\n",
      "Number of unique users: 359347\n"
     ]
    }
   ],
   "source": [
    "user_profiles = pd.read_table(\"lastfm-dataset-360K/profiles.tsv\", \n",
    "                         header=None, names=['user_id', 'gender', 'age', 'country', 'signup'])\n",
    "print(user_profiles.head(5))\n",
    "print(\"Number of rows: \" + str(len(user_profiles)))\n",
    "print(\"Number of unique users: \" + str(len(set(user_profiles['user_id'].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load user data\n",
    "The user dataset contains 358.868 individual users' Last.fm-artist listening information. \n",
    "\n",
    "![plays](img/plays.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    user_id  \\\n",
      "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "3  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "4  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "\n",
      "                              artist_id           artist_name  plays  \n",
      "0  3bd73256-3905-4f3a-97e2-8b341527f805       betty blowtorch   2137  \n",
      "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320             die Ärzte   1099  \n",
      "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa     melissa etheridge    897  \n",
      "3  3d6bbeb7-f90e-4d10-b440-e153c0d10b53             elvenking    717  \n",
      "4  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8  juliette & the licks    706  \n",
      "\n",
      "Number of rows: 17535655\n",
      "\n",
      "Number of users: 358868\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_table(\"lastfm-dataset-360K/plays.tsv\", \n",
    "                         header=None, names=['user_id', 'artist_id', 'artist_name', 'plays'])\n",
    "print(user_data.head(5))\n",
    "print(\"\\nNumber of rows: \" + str(len(user_data)))\n",
    "print(\"\\nNumber of users: \" + str(len(set(user_data['user_id'].values))))\n",
    "user_data.drop('artist_id', axis=1, inplace=True)\n",
    "\n",
    "# drop all rows where we do not have an artist name\n",
    "if user_data['artist_name'].isnull().sum() > 0:\n",
    "    user_data = user_data.dropna(axis = 0, subset = ['artist_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Reduce number of users\n",
    "* To reduce the size of the data, only German users will be considered\n",
    "* Join user-data and user-profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of German profiles: 1555720\n"
     ]
    }
   ],
   "source": [
    "german_profiles = user_profiles[user_profiles['country'] == 'Germany']\n",
    "user_data_ger_profiles = german_profiles.merge(user_data, on=\"user_id\", how='left')\n",
    "print(\"Number of German profiles: \" + str(len(user_data_ger_profiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce number of artists\n",
    "Lesser known artists will have lesser plays from fewer users, which makes the data more noisy. This might have an effect on the recommender, since there might be a high sensitivity to instances where one individual user **loves** one less known artist.\n",
    "\n",
    "To reduce this influence, we will **filter only for the most popular users**. \n",
    "\n",
    "Another advantage is that the **file size will be reduced**, leading to better performance of the model.\n",
    "\n",
    "First, we create a table containing the total plays for each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     artist_name  artist_total_plays\n",
      "0            !!!           14362.000\n",
      "1  !action pact!              85.000\n",
      "2          !cube              40.000\n",
      "3       !deladap            1148.000\n",
      "4       !distain             379.000\n",
      "Number of artists:82816\n"
     ]
    }
   ],
   "source": [
    "artist_plays = user_data_ger_profiles.groupby('artist_name')['plays'].sum().reset_index()\n",
    "artist_plays.columns = ['artist_name', 'artist_total_plays']\n",
    "print(artist_plays.head(5))\n",
    "print(\"Number of artists:\" + str(len(artist_plays['artist_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more than 83.000 artists, the probability that some artists have been played only a few times is high.\n",
    "\n",
    "Let's find a threshold to define how many plays are needed to be a popular artist in the dataset by looking at the descriptives:\n",
    "\n",
    "* The median artist only has round about 145 plays. \n",
    "* The the most popular artist has more than 2.9 million plays\n",
    "* Only 1% of the artists has around 70.000 and more plays\n",
    "\n",
    "To keep the dataset small, **I will choose a threshold of 90.000 total plays to define whether a artist is popular or not. This will reduce the number of artists to 645**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     82816.000\n",
      "mean       3649.069\n",
      "std       32286.877\n",
      "min           1.000\n",
      "25%          36.000\n",
      "50%         145.000\n",
      "75%         618.000\n",
      "max     2955844.000\n",
      "Name: artist_total_plays, dtype: float64\n",
      "\n",
      "0.980     29364.400\n",
      "0.982     33647.000\n",
      "0.984     39316.520\n",
      "0.986     46431.380\n",
      "0.988     56943.960\n",
      "0.990     69368.700\n",
      "0.992     87238.000\n",
      "0.994    114542.490\n",
      "0.996    165063.340\n",
      "0.998    276339.520\n",
      "1.000   2955844.000\n",
      "Name: artist_total_plays, dtype: float64\n",
      "82816\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "print(artist_plays['artist_total_plays'].describe())\n",
    "print(\"\")\n",
    "print(artist_plays['artist_total_plays'].quantile(np.arange(.98, 1, .002)))\n",
    "threshold = 90000\n",
    "popular_artist_plays = artist_plays[artist_plays['artist_total_plays'] > threshold]\n",
    "\n",
    "print(len(artist_plays['artist_name']))\n",
    "print(len(popular_artist_plays['artist_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring the datasets together into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       user_id gender    age  country  \\\n",
      "0     00000c289a1829a808ac09c00daf10bc3c4e223b      f 22.000  Germany   \n",
      "4507  aba29c45c5067cba15e191da456a130ed84bcb14      f 26.000  Germany   \n",
      "4479  aadcd8781ea372f3164b726ff10011d4ac73b9cc      m 32.000  Germany   \n",
      "4478  aad472ed3b7ca0df1e4efc7c9b2436f52e221519      m 18.000  Germany   \n",
      "4477  aad0cddae6587e92c7069b22d202adb99d53624e      f 15.000  Germany   \n",
      "\n",
      "            signup artist_name    plays  artist_total_plays  \n",
      "0      Feb 1, 2007   die Ärzte 1099.000         2955844.000  \n",
      "4507   Sep 6, 2007   die Ärzte 2245.000         2955844.000  \n",
      "4479  Nov 27, 2006   die Ärzte  802.000         2955844.000  \n",
      "4478  Nov 24, 2006   die Ärzte  498.000         2955844.000  \n",
      "4477  Oct 25, 2007   die Ärzte  648.000         2955844.000  \n"
     ]
    }
   ],
   "source": [
    "user_with_artist_plays = user_data_ger_profiles.merge(popular_artist_plays, on='artist_name', how='inner')\n",
    "user_with_artist_plays = user_with_artist_plays.sort_values('artist_total_plays', ascending=False)\n",
    "print(user_with_artist_plays.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct format\n",
    "The k-nearest neighbor algorithm will be used for the recommender. As a prerequesit, the data must be in a *mxn*-shaped matrix, where *n* is the number of artists and *m* is the number of users.\n",
    "\n",
    "The format we need here is: ![collabfiltering](img/icollaborative_filtering.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_artist_plays = user_with_artist_plays.drop_duplicates(['user_id', 'artist_name'])\n",
    "# pivot to create a dataframe with artists as rows and users as columns. \n",
    "# Fill with the number of plays per user and artist. Fill empty values with 0.\n",
    "wide_artist_data = user_with_artist_plays.pivot(index = 'artist_name', columns = 'user_id', values = 'artist_total_plays').fillna(0)\n",
    "# Transform to sparse matrix for more efficiency.\n",
    "wide_artist_data_sparse = csr_matrix(wide_artist_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "I will use a k-Nearest Neighbor for the recommender. \n",
    "The algorithm computes the distance between a specific artist and the remaining artists in the dataset. \n",
    "\n",
    "The smaller the distance between two instances, the more similar they are. For each artist, **the k best matches will be returned** (the ones with the smallest distance).\n",
    "\n",
    "![knn](img/knearestneighbor.jpeg)\n",
    "\n",
    "There exists a large nummber of metrics you can choose to calculate this distance: Euclidian Distance, Pearson, Cosine, etc. I will **use the cosine to calculate the distance between two items**.\n",
    "\n",
    "Let's train a NearestNeighbor-model on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=1, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'auto')\n",
    "model_knn.fit(wide_artist_data_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations\n",
    "\n",
    "We can use the model to make some recommendations.\n",
    "\n",
    "Sklearn's kneighbors-model provides an operation called *kneighbors*, which we will use here:\n",
    "* Input: [Query points X (column of our artist), number of artists k]\n",
    "* Output: [Distances between every of the k results and our query, Indices of the k nearest points in the data matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429\n",
      "[[     0.      0.      0. ...      0. 157035.      0.]]\n",
      "[0.         0.70549543 0.760319   0.7680288  0.80323174 0.82062726]\n",
      "\n",
      "Artist: ohrbooten\n",
      "Recommendation 1: mono & nikitaman - 0.7054954325066647 \n",
      "Recommendation 2: culcha candela - 0.760319003182583 \n",
      "Recommendation 3: seeed - 0.7680287997564453 \n",
      "Recommendation 4: patrice - 0.8032317368403745 \n",
      "Recommendation 5: gentleman - 0.8206272568131207 \n"
     ]
    }
   ],
   "source": [
    "query_index = np.random.choice(wide_artist_data.shape[0])\n",
    "distances, indices = model_knn.kneighbors(wide_artist_data.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 6)\n",
    "\n",
    "print(distances.flatten())\n",
    "print(\"\")\n",
    "distance_len = len(distances.flatten())\n",
    "for i in range(1, min(distance_len, distance_len + 1)):\n",
    "    if i == 1:\n",
    "        print(\"Artist: %s\" % wide_artist_data.index[query_index])\n",
    "    print(\"Recommendation %s: %s - %s \" % (i, wide_artist_data.index[indices[0][i]], distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since users will not be interested in recommendations for some random artist, the index of the artist one's looking for has to be looked up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: die toten hosen\n",
      "Recommendation 1: die Ärzte - 0.517372892477576 \n",
      "Recommendation 2: farin urlaub - 0.6454411358570306 \n",
      "Recommendation 3: rammstein - 0.6924119777968816 \n",
      "Recommendation 4: böhse onkelz - 0.6971024940724783 \n",
      "Recommendation 5: the offspring - 0.6972890602949392 \n"
     ]
    }
   ],
   "source": [
    "artist_name = \"die toten hosen\"\n",
    "artists = user_with_artist_plays['artist_name'].unique()\n",
    "artist_index = wide_artist_data.ix[artist_name].values.reshape(1, -1)\n",
    "distances, indices = model_knn.kneighbors(artist_index, n_neighbors = 6)\n",
    "\n",
    "distance_len = len(distances.flatten())\n",
    "for i in range(1, min(distance_len, distance_len + 1)):\n",
    "    if i == 1:\n",
    "        print(\"Artist: %s\" % artist_name)\n",
    "    print(\"Recommendation %s: %s - %s \" % (i, wide_artist_data.index[indices[0][i]], distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Since I want to deploy the model online, I will serialize and save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_knn, open('nn_recommender.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save available artist-names\n",
    "For my online artist-recommender, I also need the artist-name list to query for artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.DataFrame(artists)\n",
    "artists.to_csv(\"artists.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "I deployed the recommender in a simple **django-application on [Heroku](https://www.heroku.com/)**. \n",
    "The recommender can be used via a REST-API ([this website](https://denmei.github.io/) uses the API). \n",
    "\n",
    "Give it a try with [this](https://www.codepunker.com/tools/http-requests) http-request-service by making a POST-request (should be GET, I know):\n",
    "\n",
    "* **URL**: https://ml-server-dm.herokuapp.com/music_recommender/api/artist_recommendation\n",
    "* **Parameters**: \n",
    "    * artist: the name of the artist you are interested in\n",
    "    * number: the number of recommendations you want to retrieve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
