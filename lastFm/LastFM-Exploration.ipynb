{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative item-based filtering for music artists\n",
    "Within this notebook I built a recommender for music artists using a collaborative item-based filtering approach. As a basis, I used the last.fm-dataset which can be found [here](http://www.dtic.upf.edu/~ocelma/MusicRecommendationDataset/index.html). \n",
    "\n",
    "To provide a better understanding of the approach, here's a small introduction (from Wikipedia, I have to admit):\n",
    "* Collaborative filtering is the process of filtering for information or patterns using techniques involving collaboration aming multiple agents, viewpoints, data sources etc.\n",
    "* There exist different approaches for collaborative filtering:\n",
    "    * User-based: Use ratings from like-minded users to give a recommendation for the active user\n",
    "    * Item-based: Build item-item-matrix determining relationship between pairs of items -> Use tastes of current user to find similar items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import csr_matrix\n",
    "import pickle\n",
    "pd.options.display.float_format = \"{:.3f}\".format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data + Data Exploration\n",
    "\n",
    "### Load user profiles\n",
    "The user profiles dataset contains data about 359.347 different users, including their id, geneder, age, country and the data when they signed up for the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    user_id gender   age        country  \\\n",
      "0  00000c289a1829a808ac09c00daf10bc3c4e223b      f  22.0        Germany   \n",
      "1  00001411dc427966b17297bf4d69e7e193135d89      f   NaN         Canada   \n",
      "2  00004d2ac9316e22dc007ab2243d6fcb239e707d    NaN   NaN        Germany   \n",
      "3  000063d3fe1cf2ba248b9e3c3f0334845a27a6bf      m  19.0         Mexico   \n",
      "4  00007a47085b9aab8af55f52ec8846ac479ac4fe      m  28.0  United States   \n",
      "\n",
      "         signup  \n",
      "0   Feb 1, 2007  \n",
      "1   Dec 4, 2007  \n",
      "2   Sep 1, 2006  \n",
      "3  Apr 28, 2008  \n",
      "4  Jan 27, 2006  \n",
      "Number of rows: 359347\n",
      "Number of unique users: 359347\n"
     ]
    }
   ],
   "source": [
    "user_profiles = pd.read_table(\"/home/dennis/Documents/lastfm-prediction/Jupyter/lastFm/lastfm-dataset-360K/profiles.tsv\", \n",
    "                         header=None, names=['user_id', 'gender', 'age', 'country', 'signup'])\n",
    "print(user_profiles.head(5))\n",
    "print(\"Number of rows: \" + str(len(user_profiles)))\n",
    "print(\"Number of unique users: \" + str(len(set(user_profiles['user_id'].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load user data\n",
    "The user dataset contains 358.868 individual users' Last.fm-artist listening information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    user_id  \\\n",
      "0  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "1  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "2  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "3  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "4  00000c289a1829a808ac09c00daf10bc3c4e223b   \n",
      "\n",
      "                              artist_id           artist_name  plays  \n",
      "0  3bd73256-3905-4f3a-97e2-8b341527f805       betty blowtorch   2137  \n",
      "1  f2fb0ff0-5679-42ec-a55c-15109ce6e320             die Ärzte   1099  \n",
      "2  b3ae82c2-e60b-4551-a76d-6620f1b456aa     melissa etheridge    897  \n",
      "3  3d6bbeb7-f90e-4d10-b440-e153c0d10b53             elvenking    717  \n",
      "4  bbd2ffd7-17f4-4506-8572-c1ea58c3f9a8  juliette & the licks    706  \n",
      "\n",
      "Number of rows: 17535655\n",
      "\n",
      "Number of users: 358868\n"
     ]
    }
   ],
   "source": [
    "user_data = pd.read_table(\"/home/dennis/Documents/lastfm-prediction/Jupyter/lastFm/lastfm-dataset-360K/plays.tsv\", \n",
    "                         header=None, names=['user_id', 'artist_id', 'artist_name', 'plays'])\n",
    "print(user_data.head(5))\n",
    "print(\"\\nNumber of rows: \" + str(len(user_data)))\n",
    "print(\"\\nNumber of users: \" + str(len(set(user_data['user_id'].values))))\n",
    "user_data.drop('artist_id', axis=1, inplace=True)\n",
    "\n",
    "# drop all rows where we do not have an artist name\n",
    "if user_data['artist_name'].isnull().sum() > 0:\n",
    "    user_data = user_data.dropna(axis = 0, subset = ['artist_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Reduce number of users\n",
    "* To reduce the size of the data, only German users will be considered\n",
    "* Join user-data and user-profiles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of German profiles: 1555720\n"
     ]
    }
   ],
   "source": [
    "german_profiles = user_profiles[user_profiles['country'] == 'Germany']\n",
    "user_data_ger_profiles = german_profiles.merge(user_data, on=\"user_id\", how='left')\n",
    "print(\"Number of German profiles: \" + str(len(user_data_ger_profiles)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce number of artists\n",
    "Lesser known artists will have lesser plays from fewer users, which makes the data more noisy. This might have an effect on the recommender, since there might be a high sensitivity to instances where one individual user **loves** one less known artist.\n",
    "\n",
    "To reduce this influence, we will filter only for the most popular users. \n",
    "\n",
    "Another advantage is that the file size will be reduced, leading to better performance of the model.\n",
    "\n",
    "First, we create a table containing the total plays for each artist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     artist_name  artist_total_plays\n",
      "0            !!!             14362.0\n",
      "1  !action pact!                85.0\n",
      "2          !cube                40.0\n",
      "3       !deladap              1148.0\n",
      "4       !distain               379.0\n",
      "Number of artists:82816\n"
     ]
    }
   ],
   "source": [
    "artist_plays = user_data_ger_profiles.groupby('artist_name')['plays'].sum().reset_index()\n",
    "artist_plays.columns = ['artist_name', 'artist_total_plays']\n",
    "print(artist_plays.head(5))\n",
    "print(\"Number of artists:\" + str(len(artist_plays['artist_name'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more than 83.000 artists, the probability that some artists have been played only a few times is high.\n",
    "\n",
    "Let's find a threshold to define how many plays are needed to be a popular artist in the dataset by looking at the descriptives:\n",
    "\n",
    "* The median artist only has round about 145 plays. \n",
    "* The the most popular artist has more than 2.9 million plays\n",
    "* Only 1% of the artists has around 70.000 and more plays\n",
    "\n",
    "To keep the dataset small, I will choose a threshold of 90.000 total plays to define whether a artist is popular or not. This will reduce the number of artists to 645."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     82816.000\n",
      "mean       3649.069\n",
      "std       32286.877\n",
      "min           1.000\n",
      "25%          36.000\n",
      "50%         145.000\n",
      "75%         618.000\n",
      "max     2955844.000\n",
      "Name: artist_total_plays, dtype: float64\n",
      "\n",
      "0.980     29364.400\n",
      "0.982     33647.000\n",
      "0.984     39316.520\n",
      "0.986     46431.380\n",
      "0.988     56943.960\n",
      "0.990     69368.700\n",
      "0.992     87238.000\n",
      "0.994    114542.490\n",
      "0.996    165063.340\n",
      "0.998    276339.520\n",
      "1.000   2955844.000\n",
      "Name: artist_total_plays, dtype: float64\n",
      "82816\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "print(artist_plays['artist_total_plays'].describe())\n",
    "print(\"\")\n",
    "print(artist_plays['artist_total_plays'].quantile(np.arange(.98, 1, .002)))\n",
    "threshold = 90000\n",
    "popular_artist_plays = artist_plays[artist_plays['artist_total_plays'] > threshold]\n",
    "\n",
    "print(len(artist_plays['artist_name']))\n",
    "print(len(popular_artist_plays['artist_name']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's bring the datasets together into one DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       user_id gender    age  country  \\\n",
      "0     00000c289a1829a808ac09c00daf10bc3c4e223b      f 22.000  Germany   \n",
      "4507  aba29c45c5067cba15e191da456a130ed84bcb14      f 26.000  Germany   \n",
      "4479  aadcd8781ea372f3164b726ff10011d4ac73b9cc      m 32.000  Germany   \n",
      "4478  aad472ed3b7ca0df1e4efc7c9b2436f52e221519      m 18.000  Germany   \n",
      "4477  aad0cddae6587e92c7069b22d202adb99d53624e      f 15.000  Germany   \n",
      "\n",
      "            signup artist_name    plays  artist_total_plays  \n",
      "0      Feb 1, 2007   die Ärzte 1099.000         2955844.000  \n",
      "4507   Sep 6, 2007   die Ärzte 2245.000         2955844.000  \n",
      "4479  Nov 27, 2006   die Ärzte  802.000         2955844.000  \n",
      "4478  Nov 24, 2006   die Ärzte  498.000         2955844.000  \n",
      "4477  Oct 25, 2007   die Ärzte  648.000         2955844.000  \n"
     ]
    }
   ],
   "source": [
    "user_with_artist_plays = user_data_ger_profiles.merge(popular_artist_plays, on='artist_name', how='inner')\n",
    "user_with_artist_plays = user_with_artist_plays.sort_values('artist_total_plays', ascending=False)\n",
    "print(user_with_artist_plays.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct format\n",
    "The k-nearest neighbor algorithm will be used for the recommender. As a prerequesit, the data must be in a *mxn*-shaped matrix, where *m* is the number of artists and *n* is the number of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_artist_plays = user_with_artist_plays.drop_duplicates(['user_id', 'artist_name'])\n",
    "# pivot to create a dataframe with artists as rows and users as columns. \n",
    "# Fill with the number of plays per user and artist. Fill empty values with 0.\n",
    "wide_artist_data = user_with_artist_plays.pivot(index = 'artist_name', columns = 'user_id', values = 'artist_total_plays').fillna(0)\n",
    "# Transform to sparse matrix for more efficiency.\n",
    "wide_artist_data_sparse = csr_matrix(wide_artist_data.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "I will use a k-Nearest Neighbor for the recommender. The algorithm computes the distance between a specific artist and the remaining artists in the dataset. For each artist, the k closest matches will be returned. The smaller the distance between two instances, the more similar they are. There exists a large nummber of metrics you can choose to calculate this distance, I will use the cosine.\n",
    "\n",
    "![knn](img/knearestneighbor.jpeg)\n",
    "\n",
    "Let's train a NearestNeighbor-model on the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'auto')\n",
    "model_knn.fit(wide_artist_data_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations\n",
    "\n",
    "We can use the model to make some recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.43929354e-15 7.12623456e-01 7.17346387e-01 7.65405762e-01\n",
      " 7.79447172e-01 8.05203639e-01]\n",
      "Artist: trapt\n",
      "Recommendation 1: breaking benjamin - 0.7126234555909592 \n",
      "Recommendation 2: three days grace - 0.7173463867619371 \n",
      "Recommendation 3: seether - 0.7654057623144099 \n",
      "Recommendation 4: staind - 0.7794471715761426 \n",
      "Recommendation 5: adema - 0.805203639499312 \n"
     ]
    }
   ],
   "source": [
    "query_index = np.random.choice(wide_artist_data.shape[0])\n",
    "distances, indices = model_knn.kneighbors(wide_artist_data.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 6)\n",
    "\n",
    "print(distances.flatten())\n",
    "distance_len = len(distances.flatten())\n",
    "for i in range(1, min(distance_len, distance_len + 1)):\n",
    "    if i == 1:\n",
    "        print(\"Artist: %s\" % wide_artist_data.index[query_index])\n",
    "    print(\"Recommendation %s: %s - %s \" % (i, wide_artist_data.index[indices[0][i]], distances.flatten()[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model\n",
    "Since I want to deploy the model online, I will serialize and save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_knn, open('nn_recommender.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_loaded = pickle.load(open('nn_recommender.sav', 'rb'))\n",
    "distances, indices = nn_loaded.kneighbors(wide_artist_data.iloc[query_index, :].values.reshape(1, -1), n_neighbors = 6)\n",
    "print(distances.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save available artist-names\n",
    "For my online artist-recommender, I also need the artist-name list to query for artists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = user_with_artist_plays['artist_name'].unique()\n",
    "artists = pd.DataFrame(artists)\n",
    "artists.to_csv(\"artists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
